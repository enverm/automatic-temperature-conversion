{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08 - NLP - Fundamentals.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roderikmogot/automatic-temperature-conversion/blob/main/08%20-%20NLP%20-%20Fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1XJL9AstZcB"
      },
      "source": [
        "# NLP - Fundamentals\n",
        "\n",
        "NLP has the goal of deriving information out of natural language (could be sequences of text and speech).\n",
        "\n",
        "Another common for NLP problems is sequence to sequence problems (seq2seq)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgTQkErsuk_f"
      },
      "source": [
        "## Check for GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAwLwNx8unfD",
        "outputId": "a95c46e7-1c89-4028-b6fe-89fd65d9e37f"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla K80 (UUID: GPU-1eac1bc7-7d66-c3da-346e-516a44b71645)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08qcI3HDuonM"
      },
      "source": [
        "## Get helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dK1yXl4mvdnn",
        "outputId": "39b2ba9b-af60-4886-d121-4d950018a90e"
      },
      "source": [
        "!wget https://github.com/mrdbourke/tensorflow-deep-learning/raw/main/extras/helper_functions.py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-18 09:12:00--  https://github.com/mrdbourke/tensorflow-deep-learning/raw/main/extras/helper_functions.py\n",
            "Resolving github.com (github.com)... 52.69.186.44\n",
            "Connecting to github.com (github.com)|52.69.186.44|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py [following]\n",
            "--2021-09-18 09:12:01--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-09-18 09:12:01 (65.7 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG73oLoKvi-g"
      },
      "source": [
        "# Import series of helper functions for the notebook\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45sRWJuBv0DT"
      },
      "source": [
        "## Get a text dataset\n",
        "\n",
        "The dataset we're going to be using is Kaggle's introduction to NLP dataset (text samples of Tweets labelled with disaster or not)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J432bH9_wMcD",
        "outputId": "4f3b7647-1ff6-41d2-af7d-314fc7c425a7"
      },
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-18 09:12:03--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.203.128, 74.125.204.128, 64.233.189.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.203.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2021-09-18 09:12:04 (82.9 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB9yC1cZwQ7c"
      },
      "source": [
        "# Unzip the data\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgoe_1_4wYkr"
      },
      "source": [
        "## Visualizing a text dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "qm74IcsawwNE",
        "outputId": "f6401370-6441-474d-aeab-8369d513f448"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "train_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "W5qo5nJAxmr5",
        "outputId": "9e21aca5-84c9-4b28-9bad-6526ec4ece30"
      },
      "source": [
        "train_df[\"text\"][1]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Forest fire near La Ronge Sask. Canada'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "QahlZpmNxruK",
        "outputId": "804de2fb-a89c-4912-b880-872f371ca2b4"
      },
      "source": [
        "# Shuffle training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
        "train_df_shuffled.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "R26gR9GLyB3B",
        "outputId": "2abb2299-0b9b-426a-83f4-65f09a8c8d0d"
      },
      "source": [
        "# What does the test dataframe look like?\n",
        "test_df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fT83VImayTLz",
        "outputId": "a2dad837-d215-4888-9805-931c952af0fc"
      },
      "source": [
        "# How many examples of each class?\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yooxtbxLycZr",
        "outputId": "7a399251-28b3-4219-ddab-e80128f80670"
      },
      "source": [
        "# How many samples are there?\n",
        "len(train_df), len(test_df)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtJwxucmy6OK",
        "outputId": "01a2b635-a253-4ece-f0ac-a59ff76d449e"
      },
      "source": [
        "# Let's visualize some random training examples\n",
        "import random\n",
        "random_index = random.randint(0, len(train_df)-5)\n",
        "for row in train_df_shuffled[['text', 'target']][random_index:random_index+5].itertuples(): # itertuples converts the dataframe to tuples\n",
        "  _, text, target = row # _ indicates to skip a column\n",
        "  print(f\"Target: {target}\", \"real disaster\" if target > 0 else \"not real disaster\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(f\"---\\n\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0 not real disaster\n",
            "Text:\n",
            "If you dotish to blight your car go right ahead. Once it's not mine.\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 real disaster\n",
            "Text:\n",
            "the pastor was not in the scene of the accident......who was the owner of the range rover ?\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 real disaster\n",
            "Text:\n",
            "The shooting or the airplane accident  https://t.co/iECc1JDOub\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 real disaster\n",
            "Text:\n",
            "@Eazzy_P we will never know what would have happened but the govt seemed to think that their beliefs warranted the deaths of innocent japs\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 real disaster\n",
            "Text:\n",
            "Happy no one was hurt when #wmata train derailed. Also the express bus is so much better than metro rail http://t.co/7cEhNV3DKy @fox5newsdc\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isS5AnVczlvb"
      },
      "source": [
        "### Split data into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIoTfiPB0yOL"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                            train_df_shuffled['target'].to_numpy(),\n",
        "                                                                            test_size=0.1,\n",
        "                                                                            random_state=42)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yutWbOq31eK3",
        "outputId": "4c41d772-37f8-4547-f786-25c5915dd34a"
      },
      "source": [
        "# Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TY34uRee1o0z",
        "outputId": "d35d9a51-4b25-450f-fdf6-6d61f99feea9"
      },
      "source": [
        "# Check the first 10 samples \n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWHNPTEz10Wd"
      },
      "source": [
        "## Converting text into numbers\n",
        "\n",
        "When dealing with a text problem, one of the first things you'll have to do before you can build a model is to convert your text to numbers.\n",
        "\n",
        "There are a few ways to do this, normally:\n",
        "1. **Tokenization** - word level, maps each word for e.g. \"Im eating sandwich\", stores 0 for Im, 1 for eating, 2 for sandwich (could also use one hot encoding).\n",
        "\n",
        "2. **Embedding** - create a matrix of feature vectors for each token (the size of the feature vector can be defined and this embedding can be learned)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-TrQO4W2Kp3"
      },
      "source": [
        "### Using tokenization (text vectorization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-1rPPcJwUsA",
        "outputId": "6812b37d-b8b3-4c93-8342-5a8f6d4391d9"
      },
      "source": [
        "train_sentences[:5]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "       'Imagine getting flattened by Kurt Zouma',\n",
              "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "       'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "kLXSwLizwWbt",
        "outputId": "a9021d55-e3d8-4582-ce83-0db9d54b73cc"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "# This is the default TextVectorization paramters\n",
        "text_vectorizer = TextVectorization(max_tokens=None, # how many different words in the vocabulary (automatically add <OOV> if max token has reached its limit)\n",
        "                                    standardize='lower_and_strip_punctuation', \n",
        "                                    split=\"whitespace\",\n",
        "                                    ngrams=None, # create groups of n-words\n",
        "                                    output_mode=\"int\", # how to map your tokens to numbers\n",
        "                                    output_sequence_length=None, # how long do you want sequences to be\n",
        "                                    pad_to_max_tokens=True) "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-34ae9eab6235>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                                     \u001b[0moutput_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"int\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# how to map your tokens to numbers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                     \u001b[0moutput_sequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# how long do you want sequences to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                                     pad_to_max_tokens=True) \n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/preprocessing/text_vectorization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, max_tokens, standardize, split, ngrams, output_mode, output_sequence_length, pad_to_max_tokens, vocabulary, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mpad_to_max_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_to_max_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0mmask_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         output_mode=output_mode if output_mode is not None else INT)\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/preprocessing/string_lookup.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, max_tokens, num_oov_indices, mask_token, oov_token, vocabulary, encoding, invert, output_mode, sparse, pad_to_max_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mpad_to_max_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_to_max_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    326\u001b[0m     \u001b[0mbase_preprocessing_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_kpl_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"StringLookup\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/preprocessing/index_lookup.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, max_tokens, num_oov_indices, mask_token, oov_token, vocabulary, invert, output_mode, sparse, pad_to_max_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpad_to_max_tokens\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmax_tokens\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m       raise ValueError(\"If pad_to_max_tokens is True, must set `max_tokens`. \"\n\u001b[0;32m--> 170\u001b[0;31m                        \"You passed `max_tokens={}`\".format(max_tokens))\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_oov_indices\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: If pad_to_max_tokens is True, must set `max_tokens`. You passed `max_tokens=None`"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "em-Tju2F0Fz0",
        "outputId": "dcd58d2a-6ef0-4a00-c3e3-bdc8b0425b6d"
      },
      "source": [
        "len(train_sentences[0].split())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35EoLwGhws6M",
        "outputId": "84a35c1e-b831-48df-afba-67d8eeb7ff5c"
      },
      "source": [
        "# Find the average number of tokens (words) in the training tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzjiYGQc0OHk"
      },
      "source": [
        "# Setup text vectorization\n",
        "max_vocab_length = 10000 # max numbers of words in our vocab\n",
        "max_length = 15 # max length our sequences will be (e.g. how many words from a tweet does a model seek)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H16KC7ng16XN"
      },
      "source": [
        "# Fit the text vectorizer to the training set\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaatJ1jW2YIL",
        "outputId": "4e370942-31fc-4cc8-86cc-192ccb0368db"
      },
      "source": [
        "# Create a sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eTXy8B02nUC",
        "outputId": "2b0bcb35-c89b-4ddb-9cf6-236e30415f72"
      },
      "source": [
        "# Choose a random sentence from the training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text\\n{random_sentence}\\n\\nVectorized version:\")\n",
        "print(text_vectorizer([random_sentence]))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text\n",
            "California meets drought-fueled fire season with extra crews.. Related Articles: http://t.co/rKDzB0TGC3\n",
            "\n",
            "Vectorized version:\n",
            "tf.Tensor(\n",
            "[[  90 5143    1   42 1178   14 2464  689 1779 1902    1    0    0    0\n",
            "     0]], shape=(1, 15), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9wootCD3Blh",
        "outputId": "834f2424-290b-4358-ed1f-5afcabdaed31"
      },
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary() # get all of the unique words in the training data\n",
        "top_5_words = words_in_vocab[:5] # get the most common words\n",
        "bottom_5_words = words_in_vocab[-5:] # get the least common words\n",
        "print(f\"List of the 5 top words: {top_5_words}\")\n",
        "print(f\"List of the 5 bottom words: {bottom_5_words}\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of the 5 top words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "List of the 5 bottom words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BC_77txH3vAU"
      },
      "source": [
        "### Create an Embedding using an Embedding Layer\n",
        "\n",
        "To make our embedding, we're going to use TensorFlow's Embedding Layer.\n",
        "\n",
        "The parameters we care most about for our embedding layer:\n",
        "* `input_dim` = the size of our vocabulary\n",
        "* `output_dim` = the size of the output embedding vector, for example, a value of 100 would mean each token gets represented by a vector 100 long.\n",
        "* `input_length` = length of the sequences being passed to the embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjzkG3-0E5uB",
        "outputId": "c27ca757-e01d-490a-9beb-bd98c5dae23b"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
        "                             output_dim=128, # a good practice to set the numbers divisible by 8 (output shape)\n",
        "                             input_length=max_length) # how long is each input\n",
        "embedding"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7f863dbc8190>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtuJ9HtSE5W7",
        "outputId": "ff960fd6-7ea2-4216-95a1-6c90c38e421d"
      },
      "source": [
        "# Get a random sentences from the training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentence}\\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turns it into dense vectors of fixed size)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence])) # turn into integers then embed the random sentence\n",
        "sample_embed"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            " susinesses are deluged with invoices. Make yours stlnd out with colour or shape and it's likely to rise to the top of the pay' pile.\n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.00691108, -0.00782676,  0.0147694 , ..., -0.04310591,\n",
              "         -0.04552805,  0.00256777],\n",
              "        [-0.04588201, -0.0317698 ,  0.02792605, ..., -0.0166314 ,\n",
              "         -0.01492382,  0.04244467],\n",
              "        [ 0.00971549, -0.02994233,  0.01027115, ...,  0.03404461,\n",
              "          0.00729141,  0.02569329],\n",
              "        ...,\n",
              "        [ 0.00054801, -0.0133189 , -0.03000474, ..., -0.01421776,\n",
              "         -0.03873118, -0.00518841],\n",
              "        [-0.03449676,  0.01783656, -0.00612562, ...,  0.00969211,\n",
              "         -0.0066619 , -0.01365345],\n",
              "        [ 0.02778114, -0.01704999, -0.00345463, ..., -0.0263183 ,\n",
              "          0.03658184, -0.03174262]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hDxL48jHB1N"
      },
      "source": [
        "Each word in a sentence has a length of 128 and is a vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjgUwMcNGyLf",
        "outputId": "73eb10b7-213e-45a8-9ef7-e1d2346451dc"
      },
      "source": [
        "# Check out a single token's embedding\n",
        "sample_embed[0][0], sample_embed[0][0].shape, random_sentence[0]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([ 0.00691108, -0.00782676,  0.0147694 ,  0.02873111, -0.02741044,\n",
              "        -0.03764116, -0.04454966, -0.03647185,  0.0025202 ,  0.04421909,\n",
              "        -0.02993305, -0.03908554,  0.01613769, -0.01351248,  0.03852317,\n",
              "         0.0294502 ,  0.03608694, -0.01226425,  0.03618859, -0.04985463,\n",
              "        -0.03357176, -0.04119073,  0.00384299, -0.01024977,  0.02252466,\n",
              "         0.01239013,  0.02010765,  0.03902057, -0.00280292, -0.02559382,\n",
              "         0.04588095, -0.00696503, -0.03715334, -0.02911392,  0.04047424,\n",
              "        -0.02802223,  0.03660976, -0.04217859,  0.00852468,  0.02073598,\n",
              "         0.01391752,  0.04342164, -0.0105917 , -0.02029556, -0.03196885,\n",
              "        -0.01859771,  0.04979551,  0.03796807,  0.00044675, -0.04248176,\n",
              "        -0.04352742,  0.02990786,  0.02801854,  0.03384629,  0.01475144,\n",
              "        -0.0060787 , -0.00779483,  0.02998673, -0.03863081,  0.00517789,\n",
              "        -0.01369055, -0.0104328 , -0.00472982, -0.04472429, -0.03495333,\n",
              "         0.01753407, -0.04328147,  0.03793614, -0.00438955,  0.03798679,\n",
              "        -0.02854389, -0.0143685 ,  0.03869808, -0.02378551,  0.01471427,\n",
              "        -0.0474118 ,  0.04501342,  0.02381767,  0.00256085, -0.02278738,\n",
              "        -0.01776046,  0.01931597,  0.00618328, -0.03014628, -0.03310549,\n",
              "         0.01778248, -0.03786675,  0.01344632,  0.04111801, -0.00632677,\n",
              "         0.03530006, -0.03403559,  0.00055376,  0.02878137, -0.04326798,\n",
              "        -0.01963945,  0.0353794 , -0.01291401, -0.00309818,  0.03449947,\n",
              "         0.00897129,  0.01590306,  0.00476658,  0.02109269,  0.04433635,\n",
              "        -0.04627694, -0.00610941, -0.02787204, -0.03569578,  0.0470616 ,\n",
              "         0.03690176,  0.02483983, -0.02722285, -0.04533736, -0.03223717,\n",
              "        -0.03867979, -0.01108402, -0.01108264, -0.01792991, -0.04980225,\n",
              "         0.02312816,  0.02028385,  0.02715336, -0.04790523,  0.00552164,\n",
              "        -0.04310591, -0.04552805,  0.00256777], dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " 's')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yw1KRwbFHUVP"
      },
      "source": [
        "## Modelling a text dataset (and running a set of experiments)\n",
        "\n",
        "Now we've got a way to turn our text sequences into numbers, it's time to start building a series of modelling experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-4nMZ-rIVp8"
      },
      "source": [
        "![](https://raw.githubusercontent.com/roderikmogot/csv/main/Screen%20Shot%202021-09-17%20at%2013.00.21.png)\n",
        "\n",
        "Note: The guideline for creating a model is not as precise as what we need. These are just references. It may change according to your needs.\n",
        "\n",
        "How are we going to approach all of these?\n",
        "* Create the model\n",
        "* Build the model\n",
        "* Compile the model\n",
        "* Fit the model\n",
        "* Evaluate the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RuFH_8yIA2Q"
      },
      "source": [
        "### Model 0: Getting a baseline\n",
        "\n",
        "Using sklearn's Multinominal Naive Bayes using the TF-IDF formula to convert our words into numbers.\n",
        "\n",
        "> It is common practice to use non-DL algorithms as a baseline because of their speed, then later use DL if we can improve upon them.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z49m6aATIAd8",
        "outputId": "dad8d859-d48e-4d17-8d3d-243d1eab4c21"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "  (\"tfidf\", TfidfVectorizer()), # convert words to numbers using TF-IDF\n",
        "  (\"clf\", MultinomialNB()) # model the text\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waehALUbLK2R",
        "outputId": "5616f104-7073-4488-dfa6-85900ac5e05b"
      },
      "source": [
        "# Evaluate our base line model\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Our baseline model achieve an accuracy score of {baseline_score*100:.2f}%\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline model achieve an accuracy score of 79.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiX61TNpLb2t",
        "outputId": "86686a5e-2a04-44d4-84de-da9c1cf5842d"
      },
      "source": [
        "# Make predictions for base model\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb_SExB7Lyjj"
      },
      "source": [
        "#### Creating an evaluation function for our modelling experiments\n",
        "\n",
        "This includes:\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN_lcVjZMUSf"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates a model accuracy, precision, recall, f1 score of a binary classification model.\n",
        "  \"\"\"\n",
        "\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "\n",
        "  # Calculate model precision, recall and f1-score\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\") # skip for support\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                   \"precision\": model_precision,\n",
        "                   \"recall\": model_recall,\n",
        "                   \"f1\": model_f1}\n",
        "  return model_results"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOvRGuOdOGQJ",
        "outputId": "2b0abec5-d283-4d25-e9bf-7bf037f5433a"
      },
      "source": [
        "# Get baseline results\n",
        "baseline_results = calculate_results(val_labels, baseline_preds)\n",
        "baseline_results"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8QtkzsmO4AP"
      },
      "source": [
        "### Model 1: Feed-forward neural network (dense model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CpqPkfqPCOL"
      },
      "source": [
        "# Create a tensorboard callback (need to create a new one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create a directory to save TensorBoard logs\n",
        "SAVE_DIR = \"model_logs\""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgBuWcPpPfp8"
      },
      "source": [
        "# Using the Functional API\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# shape = seek one sequence at a time\n",
        "# inputs are 1-dimensional strings\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string) \n",
        "\n",
        "# turn the input text into numbers\n",
        "x = text_vectorizer(inputs)\n",
        "\n",
        "# turn our numbers into embedding\n",
        "x = embedding(x)\n",
        "\n",
        "# condense the feature vector each token to one vector\n",
        "# 1d is for sequential data (texts, etc)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "# x = layers.GlobalMaxPooling1D()(x)\n",
        "\n",
        "# Create the output, since we are dealing with binary classification,\n",
        "# the hidden unit should be 1 and activation is sigmoid\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "# Create the model\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJRwlR0nQjgT",
        "outputId": "61ed24ae-f09f-4d73-ef8c-be9000240ee8"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi26SckvQki8"
      },
      "source": [
        "# Compile the model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dH74xq8CQ6wD",
        "outputId": "053de16f-773e-436b-ca18-7025119c267c"
      },
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"model_1_dense\")])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20210918-091244\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 9ms/step - loss: 0.6097 - accuracy: 0.6964 - val_loss: 0.5337 - val_accuracy: 0.7572\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.4425 - accuracy: 0.8174 - val_loss: 0.4708 - val_accuracy: 0.7861\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.3460 - accuracy: 0.8640 - val_loss: 0.4687 - val_accuracy: 0.7874\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.2847 - accuracy: 0.8907 - val_loss: 0.4679 - val_accuracy: 0.7874\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.2378 - accuracy: 0.9108 - val_loss: 0.4758 - val_accuracy: 0.7822\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvPmc26HROM1",
        "outputId": "6c360176-caa7-4ca5-d909-511f21d79395"
      },
      "source": [
        "# Check the results\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.7822\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4757738411426544, 0.7821522355079651]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQz__i91RfJW",
        "outputId": "701d755a-7bba-4f23-b283-97f5bb50f163"
      },
      "source": [
        "# Make some predictions and evaluate those\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs[:1]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.38771936]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iny73nkVR5aS"
      },
      "source": [
        "It's not in the right format, it's actually predicting on each tokens (when not adding `GlobalAveragePooling1D` / `GlobalMaxPooling1D` layer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8P6AyVITd_m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d532b95-5a68-474b-a56c-fbf6ba802aa1"
      },
      "source": [
        "# Convert model prediction probabilities to label format\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
        "model_1_preds"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
              "       1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
              "       0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
              "       0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-qu2-3aTiuj",
        "outputId": "bf78fc3e-e541-4123-9bad-690559f9a1e7"
      },
      "source": [
        "# Calculate our model_1 results\n",
        "model_1_results = calculate_results(val_labels, model_1_preds)\n",
        "model_1_results"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.21522309711287,\n",
              " 'f1': 0.7795215466562155,\n",
              " 'precision': 0.7856661242905698,\n",
              " 'recall': 0.7821522309711286}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lw7vFP0-TwE4",
        "outputId": "40cabca6-cde4-4142-ba94-e611cca0c27f"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdPq4BLMUHBF"
      },
      "source": [
        "As we can see, the baseline result is still higher than most of `model_1`'s evaluation metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpEHfmART7b1"
      },
      "source": [
        "## Visualizing learned embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSShr3OGaOFN",
        "outputId": "4ca0883d-2dd7-4a79-fdef-e10990722b37"
      },
      "source": [
        "# Get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMsI_ScfagZM",
        "outputId": "e3ac6b41-ed45-4b78-ebc6-fe2e1d619f45"
      },
      "source": [
        "# Model 1 summary\n",
        "model_1.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWPJZMxIaurE",
        "outputId": "a50629f5-6b13-4ba6-9a5d-cd9ba1ee29eb"
      },
      "source": [
        "# Get the weight matrix of embedding layer\n",
        "# (these are the numerical representations of each token in our training data , which have been learned for 5 epochs)\n",
        "embed_weights = model_1.get_layer(\"embedding\").get_weights()[0]\n",
        "embed_weights.shape # same size as vocab size and embedding dim"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjZ3b4s9bxWn"
      },
      "source": [
        "Now we've got the embdding matrix our model has learned to represent our tokens, let's see how we can visualize it..\n",
        "\n",
        "TensorFlow Projector: https://projector.tensorflow.org/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "al8qCebvbJuR",
        "outputId": "0d34ae05-2ae9-44d6-c2ce-ea503a190d83"
      },
      "source": [
        "embed_weights"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.04038535,  0.03420018,  0.00450342, ..., -0.01996917,\n",
              "        -0.00285624, -0.05126059],\n",
              "       [ 0.02640555,  0.00330343,  0.02252487, ...,  0.02207453,\n",
              "        -0.0333004 , -0.02817232],\n",
              "       [ 0.05701675, -0.02700342,  0.04861306, ...,  0.00129554,\n",
              "        -0.00276819, -0.02809346],\n",
              "       ...,\n",
              "       [ 0.04971788,  0.04712025,  0.00607764, ..., -0.0489416 ,\n",
              "         0.02565788,  0.02764216],\n",
              "       [ 0.03394805,  0.04099939,  0.05055056, ..., -0.05841227,\n",
              "        -0.07896879, -0.02528039],\n",
              "       [ 0.02575956,  0.09229694,  0.09899379, ..., -0.04370059,\n",
              "        -0.08375761, -0.06667635]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HfT1g4nbrW5"
      },
      "source": [
        "# Create embedding files (from TF word embeddings docs)\n",
        "import io\n",
        "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(words_in_vocab):\n",
        "  if index == 0:\n",
        "    continue  # skip 0, it's padding.\n",
        "  vec = embed_weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "dBaYbrS8c2F8",
        "outputId": "bdb64b86-c3df-4204-821b-0e09ea0dfac7"
      },
      "source": [
        "# Download files from colab to projector\n",
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('vectors.tsv')\n",
        "  files.download('metadata.tsv')\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_917d5d69-af6d-4d18-abed-44af47aabf7e\", \"vectors.tsv\", 15369494)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_31a8bd32-49e0-452d-8e5a-429c4194cd94\", \"metadata.tsv\", 80388)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azdHjJ3sdu8N"
      },
      "source": [
        "## Recurrent Neural Network\n",
        "\n",
        "RNN's are useful for sequence data (like text).\n",
        "\n",
        "The premise of a recurrent neural network is to use the representation\n",
        "of a previous input to aid the representation of a later input.\n",
        "\n",
        "\"The premise of\" in RNN reads the \"The\"  for a representation of \"premise\" then later uses \"The premise\" as a representation to represent \"of\" and so on.\n",
        "\n",
        "> An overview of recurrent neural network:\n",
        "* MIT - https://youtu.be/qjrad0V0uJE\n",
        "* Andrej Karpathy - demonstrates the power of RNN's with examples generating various sequences - http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
        "* Chris Olah - an in-depth (and technical) look at the mechanics of the LSTM cell, possibly the most popular RNN building block - https://colah.github.io/posts/2015-08-Understanding-LSTMs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcfXT5cvfqO5"
      },
      "source": [
        "### Model 2: LSTM\n",
        "\n",
        "LSTM = long short term memory (one of the most popular LSTM cells)\n",
        "\n",
        "Our structure of an RNN typically looks like this:\n",
        "```\n",
        "Input (text) -> Tokenize -> Embedding -> Layers (RNN/dense) -> Output (label probability)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjlyvPjPiTde"
      },
      "source": [
        "# Create an LSTM model\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# print(x.shape)\n",
        "\n",
        "# when you're stacking RNN cells together, you need to return_sequences=True\n",
        "x = layers.LSTM(units=64, return_sequences=True)(x)\n",
        "# print(x.shape)\n",
        "x = layers.LSTM(64)(x)\n",
        "# print(x.shape)\n",
        "\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "# print(x.shape)\n",
        "\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwJybZO3jl6w",
        "outputId": "d0cb649b-4076-4033-8e0e-78e6fc032d2f"
      },
      "source": [
        "# Get a summary\n",
        "model_2.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 15, 64)            49408     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,366,657\n",
            "Trainable params: 1,366,657\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upOmfiYalK3h"
      },
      "source": [
        "# Compile the model\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTtUmzSXlWuZ",
        "outputId": "223142b9-7034-4f43-bd4b-dc1d9fb73b71"
      },
      "source": [
        "# Fit the model\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"model_2_lstm\")])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_lstm/20210918-091257\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 11s 22ms/step - loss: 0.2297 - accuracy: 0.9223 - val_loss: 0.5740 - val_accuracy: 0.7808\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.1592 - accuracy: 0.9412 - val_loss: 0.7512 - val_accuracy: 0.7822\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.1326 - accuracy: 0.9515 - val_loss: 0.7419 - val_accuracy: 0.7848\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.1065 - accuracy: 0.9609 - val_loss: 0.9135 - val_accuracy: 0.7756\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.0873 - accuracy: 0.9656 - val_loss: 0.8727 - val_accuracy: 0.7822\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a0UdC2XlkRs",
        "outputId": "1e05920e-44c1-4c50-d0b0-6907ac138014"
      },
      "source": [
        "# Make predictions with LSTM model\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7.0068501e-03],\n",
              "       [7.8592575e-01],\n",
              "       [9.9988711e-01],\n",
              "       [8.2312226e-03],\n",
              "       [2.1613749e-04],\n",
              "       [9.9361527e-01],\n",
              "       [8.0835283e-01],\n",
              "       [9.9991417e-01],\n",
              "       [9.9976236e-01],\n",
              "       [3.0117580e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIKx6TkAlxrj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e71749-ece4-4f6b-e2f9-b3fa5788146c"
      },
      "source": [
        "# Convert model 2 pred probs to labels\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
              "       0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
              "       1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
              "       0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
              "       0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
              "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
              "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
              "       0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0.],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-nHMKoxl8KW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1c1a776-e55b-4efd-81f5-a449f1c3c40a"
      },
      "source": [
        "val_labels"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
              "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
              "       1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
              "       1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
              "       1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "       0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
              "       0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
              "       0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "       1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "       1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n",
              "       1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
              "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wADcw7Hbl8xN",
        "outputId": "f951d6aa-9ca1-4e70-a46a-fbccd449251e"
      },
      "source": [
        "# Calculate model 2 results\n",
        "model_2_results = calculate_results(val_labels, model_2_preds)\n",
        "model_2_results"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.21522309711287,\n",
              " 'f1': 0.7789371307867892,\n",
              " 'precision': 0.7872762884426117,\n",
              " 'recall': 0.7821522309711286}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWjTQUVZmDG_",
        "outputId": "f37b7e90-82b0-48c9-e819-ff3e77bf8c77"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hunnrc43mI9B"
      },
      "source": [
        "Our baseline is still higher the RNN model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWEOcfdPmGwD"
      },
      "source": [
        "### Model 3: GRU\n",
        "\n",
        "Another popular and effective RNN component is the GRU or Gated Recurrent Unit.\n",
        "\n",
        "It has similar features to an LSTM cell but has less parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0sLOCDNEQsw"
      },
      "source": [
        "# Build an RNN using the GRU cell\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# print(x.shape)\n",
        "\n",
        "x = layers.GRU(64)(x)\n",
        "\n",
        "# if you want to stack recurrent layers on top of each other, return_sequences=True\n",
        "# x = layers.GRU(64, return_sequences=True)(x)\n",
        "# print(x.shape)\n",
        "# x = layers.LSTM(64, return_sequences=True)(x)\n",
        "# print(x.shape)\n",
        "\n",
        "# print(x.shape)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x)\n",
        "\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Emp64vfvGusK"
      },
      "source": [
        "Always check the shape of each layer when facing problems/errors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJMSTOGIFwhm",
        "outputId": "5a73cad6-41b9-4f85-f5f6-43a5629dcd23"
      },
      "source": [
        "# Model 3 summary\n",
        "model_3.summary()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 64)                37248     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,317,313\n",
            "Trainable params: 1,317,313\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJq8cSopG5ty"
      },
      "source": [
        "# Compile the model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiXexbzcHuvx",
        "outputId": "8dc0f992-59d9-4fdf-8f6f-438b5cba3b41"
      },
      "source": [
        "# Fit the model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"model_3_GRU\")])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_3_GRU/20210918-091322\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 14ms/step - loss: 0.1535 - accuracy: 0.9402 - val_loss: 0.7355 - val_accuracy: 0.7808\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.0839 - accuracy: 0.9691 - val_loss: 0.7293 - val_accuracy: 0.7717\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.0735 - accuracy: 0.9712 - val_loss: 0.9628 - val_accuracy: 0.7703\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0633 - accuracy: 0.9743 - val_loss: 1.0009 - val_accuracy: 0.7690\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0543 - accuracy: 0.9750 - val_loss: 1.0399 - val_accuracy: 0.7717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJ4ZonKRH-MG",
        "outputId": "43e57f22-dca0-4815-fafd-ba469287feee"
      },
      "source": [
        "# Make some predictions with our GRU model\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs[:5]"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8.0383457e-03],\n",
              "       [7.2788584e-01],\n",
              "       [9.9988306e-01],\n",
              "       [4.8031613e-02],\n",
              "       [1.2593989e-04]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuO5wOO5IGj6",
        "outputId": "934bca98-6e80-4f0f-a3ab-902b97d03b47"
      },
      "source": [
        "# Convert model 3 pred probs to labels\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIz95b8aIZSe",
        "outputId": "b7377fbf-29c5-4ad0-cd03-e53d07783f56"
      },
      "source": [
        "# Model 3 results\n",
        "results_model_3 = calculate_results(val_labels, model_3_preds)\n",
        "results_model_3"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.16535433070865,\n",
              " 'f1': 0.7702930138828643,\n",
              " 'precision': 0.7720646185150423,\n",
              " 'recall': 0.7716535433070866}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IERF2WFRInD1"
      },
      "source": [
        "It's lower than our base model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULPbOY7KLGoc"
      },
      "source": [
        "### Model 4: Bidirectional-LSTM\n",
        "\n",
        "Normal RNN's go from left to right (just like reading a sentence). However, bidirectional RNN goes from left to right as well as left to right."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j1H5oVQLTUL"
      },
      "source": [
        "# Build a bidirectional RNN in TensorFlow\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.GRU(64))(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_bidirectional\")"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cy_r9o6o3mEv",
        "outputId": "b2266065-4eab-4aa7-a43f-204881d66125"
      },
      "source": [
        "# Get a summary\n",
        "model_4.summary()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_bidirectional\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 15, 128)           98816     \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 128)               74496     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,453,441\n",
            "Trainable params: 1,453,441\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebtWbPKU35Zc"
      },
      "source": [
        "Bidirectional is going from left to right and right to left so it goes 2 directions (double the value of 64 which is 128)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kddWdiAW3rM5"
      },
      "source": [
        "# Compile model\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEFfdnAh4lnG",
        "outputId": "a6c43c69-708b-41be-d942-6db94c11debd"
      },
      "source": [
        "# Fit the model\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\"model_4_bidirectional\")])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20210918-091338\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 14s 34ms/step - loss: 0.0979 - accuracy: 0.9661 - val_loss: 1.1088 - val_accuracy: 0.7598\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 5s 24ms/step - loss: 0.0604 - accuracy: 0.9750 - val_loss: 1.3698 - val_accuracy: 0.7782\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 5s 24ms/step - loss: 0.0499 - accuracy: 0.9790 - val_loss: 1.2618 - val_accuracy: 0.7625\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 5s 24ms/step - loss: 0.0439 - accuracy: 0.9794 - val_loss: 1.4324 - val_accuracy: 0.7664\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 5s 24ms/step - loss: 0.0382 - accuracy: 0.9810 - val_loss: 1.5880 - val_accuracy: 0.7703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y54Cco0359WO",
        "outputId": "0f5d9d44-6411-4e02-bd56-cd5b979b0b95"
      },
      "source": [
        "# Make predictions with model 4\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.0517446e-05],\n",
              "       [8.7789804e-01],\n",
              "       [9.9990690e-01],\n",
              "       [1.4385673e-01],\n",
              "       [6.3468683e-06],\n",
              "       [9.9972540e-01],\n",
              "       [9.7327709e-01],\n",
              "       [9.9993312e-01],\n",
              "       [9.9990070e-01],\n",
              "       [9.9701846e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq7xfmzX6Afm",
        "outputId": "477722eb-2104-47e4-accb-c35faaa85e67"
      },
      "source": [
        "# Convert pred probs to pred labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKy1jfs56JNG",
        "outputId": "c5231a41-3c19-48bf-dd33-57491955b1cc"
      },
      "source": [
        "# Calculate model 4 results\n",
        "model_4_results = calculate_results(val_labels, model_4_preds)\n",
        "model_4_results"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.03412073490814,\n",
              " 'f1': 0.768571140634933,\n",
              " 'precision': 0.7713700595744248,\n",
              " 'recall': 0.7703412073490814}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slrtguqI6WF8"
      },
      "source": [
        "It still has not beat our baseline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e5il56o6U_t"
      },
      "source": [
        "## CNN for Text (and other types of sequences)\n",
        "\n",
        "We've used CNNs for images but images are typically 2D, however, our text data is 1D.\n",
        "\n",
        "```\n",
        "Inputs (text) -> Tokenization -> Embedding -> Layer(s) (typically Conv1D, Pooling) -> Outputs (class probability)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUzU3KTQ7Q84"
      },
      "source": [
        "### Model 5: Conv1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC4sdj--8I2W",
        "outputId": "21eb59d7-e6d3-4ec3-be29-f576088337fc"
      },
      "source": [
        "# Test out our embedding layer, Conv1D and MaxPooling\n",
        "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"])) # turn sequences into embeddings\n",
        "conv_1d = layers.Conv1D(filters=32,\n",
        "                        kernel_size=5, # looks at 5 words at a time (referred to as an ngram of 5)\n",
        "                        strides=1, # default\n",
        "                        activation=\"relu\",\n",
        "                        padding=\"valid\") # default = `valid`, the output is smaller than the input shape, `same` means the same shape as the input\n",
        "conv_1d_output = conv_1d(embedding_test) # pass test embedding to conv1d layer\n",
        "max_pool = layers.GlobalMaxPool1D()\n",
        "max_pool_outputs = max_pool(conv_1d_output) # get the most important feature (highest value)\n",
        "\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_outputs.shape"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRG8LZWD9xC9"
      },
      "source": [
        "15 becomes 11 is the effect from the `padding` which is `valid`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEIyFabH9h8A",
        "outputId": "0053310d-7442-4afb-8cbb-2bf3de4a9a95"
      },
      "source": [
        "embedding_test"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.06834625,  0.01857894,  0.02726735, ...,  0.0447961 ,\n",
              "         -0.01110186, -0.02441898],\n",
              "        [-0.02775057,  0.02696397,  0.02623237, ...,  0.01271159,\n",
              "          0.02439389,  0.02277542],\n",
              "        [ 0.02112631, -0.03437128, -0.02020492, ...,  0.04811535,\n",
              "          0.02794605, -0.03309525],\n",
              "        ...,\n",
              "        [-0.01272911,  0.01913165,  0.0103587 , ..., -0.0073108 ,\n",
              "         -0.01315095, -0.0092319 ],\n",
              "        [-0.01272911,  0.01913165,  0.0103587 , ..., -0.0073108 ,\n",
              "         -0.01315095, -0.0092319 ],\n",
              "        [-0.01272911,  0.01913165,  0.0103587 , ..., -0.0073108 ,\n",
              "         -0.01315095, -0.0092319 ]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmpZhA3y_rT_",
        "outputId": "bce83452-4465-43e4-8d52-d53a1da695fc"
      },
      "source": [
        "conv_1d_output"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 11, 32), dtype=float32, numpy=\n",
              "array([[[0.        , 0.        , 0.        , 0.        , 0.0219211 ,\n",
              "         0.07322308, 0.        , 0.00932742, 0.        , 0.        ,\n",
              "         0.05983726, 0.03443365, 0.        , 0.        , 0.01858686,\n",
              "         0.        , 0.        , 0.0324249 , 0.04247432, 0.        ,\n",
              "         0.        , 0.        , 0.00189968, 0.        , 0.        ,\n",
              "         0.04064514, 0.        , 0.02927449, 0.        , 0.10891869,\n",
              "         0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.02095161, 0.09054084, 0.02607304, 0.0058636 , 0.01596982,\n",
              "         0.07574125, 0.06468708, 0.04892814, 0.0293919 , 0.        ,\n",
              "         0.        , 0.        , 0.02770379, 0.0673148 , 0.03604815,\n",
              "         0.0248731 , 0.01396381, 0.06471038, 0.        , 0.        ,\n",
              "         0.03579373, 0.        , 0.        , 0.002567  , 0.02352376,\n",
              "         0.        , 0.03636532],\n",
              "        [0.04436423, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.01219901, 0.        , 0.05283885,\n",
              "         0.07541911, 0.03793392, 0.        , 0.05806279, 0.        ,\n",
              "         0.00134525, 0.        , 0.08787352, 0.04227187, 0.04301447,\n",
              "         0.        , 0.        , 0.00179731, 0.02539345, 0.06195664,\n",
              "         0.02164538, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.0167264 ],\n",
              "        [0.        , 0.        , 0.03996251, 0.01062249, 0.00911298,\n",
              "         0.        , 0.        , 0.03110426, 0.        , 0.05159268,\n",
              "         0.01706326, 0.        , 0.        , 0.01886109, 0.        ,\n",
              "         0.        , 0.01643844, 0.        , 0.03200517, 0.01199071,\n",
              "         0.        , 0.        , 0.        , 0.03811498, 0.        ,\n",
              "         0.02168289, 0.        , 0.        , 0.        , 0.01074286,\n",
              "         0.        , 0.05287734],\n",
              "        [0.        , 0.01304491, 0.        , 0.        , 0.01090912,\n",
              "         0.00870831, 0.        , 0.        , 0.        , 0.00523983,\n",
              "         0.0204097 , 0.04368136, 0.        , 0.05496013, 0.0028417 ,\n",
              "         0.        , 0.0263267 , 0.02045699, 0.        , 0.02775642,\n",
              "         0.02062837, 0.        , 0.        , 0.02141033, 0.04290755,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.027693  ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.02201198, 0.        , 0.        , 0.03834641,\n",
              "         0.03195072, 0.01070973, 0.        , 0.05070414, 0.        ,\n",
              "         0.        , 0.00181225, 0.03191274, 0.        , 0.00894449,\n",
              "         0.01131163, 0.0008855 , 0.00048935, 0.        , 0.00117232,\n",
              "         0.00906923, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.0157    ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.02201199, 0.        , 0.        , 0.0383464 ,\n",
              "         0.03195072, 0.01070973, 0.        , 0.05070415, 0.        ,\n",
              "         0.        , 0.00181225, 0.03191274, 0.        , 0.00894448,\n",
              "         0.01131164, 0.0008855 , 0.00048936, 0.        , 0.00117232,\n",
              "         0.00906923, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.0157    ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.02201197, 0.        , 0.        , 0.0383464 ,\n",
              "         0.03195071, 0.01070973, 0.        , 0.05070415, 0.        ,\n",
              "         0.        , 0.00181225, 0.03191274, 0.        , 0.00894449,\n",
              "         0.01131164, 0.0008855 , 0.00048934, 0.        , 0.00117233,\n",
              "         0.00906922, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.0157    ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.02201198, 0.        , 0.        , 0.0383464 ,\n",
              "         0.03195073, 0.01070973, 0.        , 0.05070415, 0.        ,\n",
              "         0.        , 0.00181225, 0.03191274, 0.        , 0.00894449,\n",
              "         0.01131164, 0.0008855 , 0.00048935, 0.        , 0.00117233,\n",
              "         0.00906922, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.0157    ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.02201199, 0.        , 0.        , 0.0383464 ,\n",
              "         0.03195072, 0.01070974, 0.        , 0.05070415, 0.        ,\n",
              "         0.        , 0.00181225, 0.03191274, 0.        , 0.00894449,\n",
              "         0.01131164, 0.0008855 , 0.00048935, 0.        , 0.00117233,\n",
              "         0.00906923, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.0157    ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.02201198, 0.        , 0.        , 0.03834641,\n",
              "         0.03195071, 0.01070973, 0.        , 0.05070416, 0.        ,\n",
              "         0.        , 0.00181224, 0.03191274, 0.        , 0.00894449,\n",
              "         0.01131164, 0.0008855 , 0.00048935, 0.        , 0.00117233,\n",
              "         0.00906923, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.0157    ]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkTH1-tr_tfu"
      },
      "source": [
        "Why it has many zeros?\n",
        "\n",
        "`relu` converts negative to integers to zero."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mM4L-61q_slK",
        "outputId": "de4ab55e-9400-42b1-c739-1bf6c5327e12"
      },
      "source": [
        "max_pool_outputs"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
              "array([[0.04436423, 0.01304491, 0.03996251, 0.01062249, 0.0219211 ,\n",
              "        0.07322308, 0.09054084, 0.03110426, 0.0058636 , 0.05283885,\n",
              "        0.07574125, 0.06468708, 0.04892814, 0.05806279, 0.01858686,\n",
              "        0.00134525, 0.0263267 , 0.08787352, 0.0673148 , 0.04301447,\n",
              "        0.0248731 , 0.01396381, 0.06471038, 0.03811498, 0.06195664,\n",
              "        0.04064514, 0.        , 0.02927449, 0.002567  , 0.10891869,\n",
              "        0.        , 0.05287734]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ8XVZj3_6MV"
      },
      "source": [
        "# Build our CNN 1D model\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Conv1D(filters=64,\n",
        "                  kernel_size=5,\n",
        "                  strides=1,\n",
        "                  activation=\"relu\",\n",
        "                  padding=\"valid\")(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_CNN1D\")"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUBZoU-lBn97",
        "outputId": "501eaf02-fd3d-4097-c7dd-9c7d1450f151"
      },
      "source": [
        "# Get the summary\n",
        "model_5.summary()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_CNN1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 11, 64)            41024     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,321,089\n",
            "Trainable params: 1,321,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oY52rZGA_MT"
      },
      "source": [
        "# Compile the model\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=\"adam\",\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "il4ta4H8BLmM",
        "outputId": "f0381cb2-5247-49f4-ff51-fbf389b676b2"
      },
      "source": [
        "# Fit the model\n",
        "model_5_history = model_5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"model_5_CNN1D\")])"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_5_CNN1D/20210918-091439\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 10ms/step - loss: 0.1552 - accuracy: 0.9472 - val_loss: 0.8873 - val_accuracy: 0.7690\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.0880 - accuracy: 0.9670 - val_loss: 1.0189 - val_accuracy: 0.7598\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.0676 - accuracy: 0.9726 - val_loss: 1.2018 - val_accuracy: 0.7612\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.0584 - accuracy: 0.9759 - val_loss: 1.3440 - val_accuracy: 0.7533\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.0514 - accuracy: 0.9777 - val_loss: 1.4574 - val_accuracy: 0.7507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBfsZNg5BuPs",
        "outputId": "4e5bf620-dc3a-4bad-bd35-21cd64391aac"
      },
      "source": [
        "# Make predictions using CNN1D model\n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:5]"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.1498628e-01],\n",
              "       [8.4173256e-01],\n",
              "       [9.9999666e-01],\n",
              "       [9.6500017e-02],\n",
              "       [3.7146275e-08]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OfGHUntB7xQ",
        "outputId": "c5ef2114-1af3-4d6f-f02e-7e1310fc8ebf"
      },
      "source": [
        "# Convert our predictions\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqdA-RLhCG_c",
        "outputId": "dabb7746-95b2-4b1c-def5-4e935546e1a5"
      },
      "source": [
        "# Evaluate model 5 results\n",
        "model_5_results = calculate_results(val_labels, model_5_preds)\n",
        "model_5_results"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.06561679790026,\n",
              " 'f1': 0.7500861597764454,\n",
              " 'precision': 0.7501834475789994,\n",
              " 'recall': 0.7506561679790026}"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD99G0C4CQIv"
      },
      "source": [
        "It still has not beat our baseline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nuq5chIcCPVj"
      },
      "source": [
        "## Model 6: TensorFlow Hub Pretrained Sentence Encoder\n",
        "\n",
        "Using transfer learning for NLP, specifically using TF Hub Universal Sentence Encoder.\n",
        "\n",
        "Great resources for feature extraction:\n",
        "* TensorFlow Hub\n",
        "* Hugging Face (https://huggingface.com/models)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MyQG7RkHHXFj",
        "outputId": "0c0ae742-5680-4402-a099-3ce421870cd8"
      },
      "source": [
        "sample_sentence"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"There's a flood in my street!\""
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiMOYT5VEewu",
        "outputId": "46243a67-fc24-462b-a1be-abfcfd9da6f1"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "embed_samples = embed([sample_sentence, \"When you call the universal sentence encoder on a sentences, it turns it into numebers.\"])\n",
        "print(embed_samples[0][:50])"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[-0.01157024  0.0248591   0.0287805  -0.01271502  0.03971543  0.08827759\n",
            "  0.02680986  0.05589837 -0.01068731 -0.0059729   0.00639324 -0.01819523\n",
            "  0.00030817  0.09105891  0.05874644 -0.03180627  0.01512476 -0.05162928\n",
            "  0.00991369 -0.06865346 -0.04209306  0.0267898   0.03011008  0.00321069\n",
            " -0.00337969 -0.04787359  0.02266718 -0.00985924 -0.04063614 -0.01292095\n",
            " -0.04666384  0.056303   -0.03949255  0.00517685  0.02495828 -0.07014439\n",
            "  0.02871508  0.04947682 -0.00633971 -0.08960191  0.02807117 -0.00808362\n",
            " -0.01360601  0.05998649 -0.10361786 -0.05195372  0.00232955 -0.02332528\n",
            " -0.03758105  0.0332773 ], shape=(50,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JieilmIfG7Ma"
      },
      "source": [
        "# Create a Keras Layer using the USE pretraiend layer from TF Hub\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[], # \n",
        "                                        dtype=\"string\", \n",
        "                                        trainable=False,\n",
        "                                        name=\"USE\")"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKvgtmTtIS4Y",
        "outputId": "a3d43d04-12eb-4b19-b5b6-af8cd6746e57"
      },
      "source": [
        "# Create model using the Sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "  sentence_encoder_layer,\n",
        "  layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(1, activation=\"sigmoid\")\n",
        "], name=\"model_6_USE\")\n",
        "\n",
        "# Compile the model\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=\"adam\",\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Get the summary\n",
        "model_6.summary()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzL6xhrgI5up",
        "outputId": "b443ff4a-1431-47aa-e48c-e2ea5db3578a"
      },
      "source": [
        "# Train a classifier on top of USE pretrained embeddings\n",
        "model_6_history = model_6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"tf_hub_sentence_encoder\")])"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20210918-091515\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 9s 31ms/step - loss: 0.5048 - accuracy: 0.7841 - val_loss: 0.4502 - val_accuracy: 0.7966\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.4141 - accuracy: 0.8146 - val_loss: 0.4379 - val_accuracy: 0.8097\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.4020 - accuracy: 0.8212 - val_loss: 0.4360 - val_accuracy: 0.8163\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.3941 - accuracy: 0.8263 - val_loss: 0.4306 - val_accuracy: 0.8110\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.3872 - accuracy: 0.8264 - val_loss: 0.4278 - val_accuracy: 0.8136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUVWjmmjJQXO",
        "outputId": "256cd544-ffb1-44f6-fcb9-f0e7f9c99575"
      },
      "source": [
        "# Make predictions\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred_probs[:10]"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.16432972],\n",
              "       [0.8326194 ],\n",
              "       [0.9904422 ],\n",
              "       [0.19454592],\n",
              "       [0.78827316],\n",
              "       [0.7703925 ],\n",
              "       [0.98388493],\n",
              "       [0.9840136 ],\n",
              "       [0.9521202 ],\n",
              "       [0.1067033 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwjfI5vJJeV1",
        "outputId": "e405ffc7-c1ed-419b-d32f-3f92d16d8b6c"
      },
      "source": [
        "# Convert predictions probabilities to labels\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10] "
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nZhJnD4Jl6J",
        "outputId": "605e3fee-172e-40ca-ba39-c9697321a881"
      },
      "source": [
        "# Evaluate model 6\n",
        "model_6_results = calculate_results(val_labels, model_6_preds)\n",
        "model_6_results"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.36482939632546,\n",
              " 'f1': 0.8126248998925568,\n",
              " 'precision': 0.8145308821695579,\n",
              " 'recall': 0.8136482939632546}"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M68Rrli6J3N3"
      },
      "source": [
        "It merely beats the baseline, but we're still not satisfied.\n",
        "\n",
        "After adding `layers.Dense(64, activation=\"relu\")`, it slightly beats the baseline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IvsVPoYJr42",
        "outputId": "6290d678-a646-41b9-9701-380b18d79252"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lpS1lXiJ1Hn"
      },
      "source": [
        "## Model 7: TF Hub Pretrained but with 10% of training data\n",
        "\n",
        "Transfer learning really helps when you have a large dataset.\n",
        "\n",
        "To see how our model performs on a smaller dataset, let's try to run the model with 10% of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pke89pMjMDNQ"
      },
      "source": [
        "## NOTE: Making data splits like below leads to data leakage (model_7 trained on 10% data, outperforms model_6 train on 100% data)\n",
        "## DO NOT MAKE DATA SPLITS WHICH LEAK DATA FROM VALIDATION DATA/TEST SETS INTO TRAINING SET\n",
        "\n",
        "# Create subsets of 10% of the training data\n",
        "# train_10_precent = train_df_shuffled[[\"text\", \"target\"]].sample(frac=0.1, random_state=42)\n",
        "# train_sentences_10_percent = train_10_precent[\"text\"].to_list()\n",
        "# train_labels_10_percent = train_10_precent[\"target\"].to_list()\n",
        "# len(train_sentences_10_percent), len(train_labels_10_percent)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zHoYWc2SlOx"
      },
      "source": [
        "# Making a better dataset (no data leakage)\n",
        "train_10_percent_split = int(0.1*len(train_sentences))\n",
        "train_sentences_10_percent = train_sentences[:train_10_percent_split]\n",
        "train_labels_10_percent = train_labels[:train_10_percent_split]"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NepJZJA9MINe",
        "outputId": "351b4891-6c9f-4091-c95b-e53bb219d51e"
      },
      "source": [
        "# Check the number of targets in our subset of data\n",
        "train_df_shuffled['target'].value_counts()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ru20cbuWM8Hn",
        "outputId": "7d2bac06-f488-48c2-991b-b704710982e7"
      },
      "source": [
        "train_df_shuffled['target'].value_counts()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzCXAq1kNOnY",
        "outputId": "bc88f3e6-d2b2-4590-abc1-a623dc69b645"
      },
      "source": [
        "# Create model 7 just like model 6\n",
        "# can also clone model 6 using TF's clone method\n",
        "model_7 = tf.keras.Sequential([\n",
        "  sentence_encoder_layer,\n",
        "  layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(1, activation=\"sigmoid\")\n",
        "], name=\"model_7_10_percent_data\")\n",
        "\n",
        "# Compile the model\n",
        "model_7.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=\"adam\",\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Get the summary\n",
        "model_7.summary()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7_10_percent_data\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMeQjLKzNF2Y",
        "outputId": "80963364-7b8f-4502-e38b-f353371f09b1"
      },
      "source": [
        "# Fit the model with 10 percent of the data\n",
        "model_7_history = model_7.fit(train_sentences_10_percent,\n",
        "                              train_labels_10_percent,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"tf_hub_USE_10_percent_data_correct_split\")])"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_USE_10_percent_data_correct_split/20210918-091623\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 4s 120ms/step - loss: 0.6668 - accuracy: 0.6964 - val_loss: 0.6440 - val_accuracy: 0.7467\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.5971 - accuracy: 0.8102 - val_loss: 0.5833 - val_accuracy: 0.7835\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 1s 31ms/step - loss: 0.5235 - accuracy: 0.8146 - val_loss: 0.5345 - val_accuracy: 0.7835\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 1s 33ms/step - loss: 0.4638 - accuracy: 0.8161 - val_loss: 0.4996 - val_accuracy: 0.7808\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 1s 46ms/step - loss: 0.4228 - accuracy: 0.8350 - val_loss: 0.4883 - val_accuracy: 0.7835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3ZQM8GZO-hx",
        "outputId": "8b186df4-80b9-414b-f11e-5c7e34fb1f92"
      },
      "source": [
        "# Make predictions\n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "model_7_pred_probs[:10]"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.19673628],\n",
              "       [0.60231924],\n",
              "       [0.9088641 ],\n",
              "       [0.39533937],\n",
              "       [0.547047  ],\n",
              "       [0.6754062 ],\n",
              "       [0.8819838 ],\n",
              "       [0.80583024],\n",
              "       [0.82581735],\n",
              "       [0.14969134]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMsv-hdLPH7E",
        "outputId": "2d7b8e23-8b92-41de-a007-ef898e95d9f8"
      },
      "source": [
        "# Convert predictions to labels\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds[:10]"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPbqj9p4PQoA",
        "outputId": "782c236c-fba3-4a60-b4aa-a275e231d644"
      },
      "source": [
        "# Evaluate model 7 metrics\n",
        "model_7_results = calculate_results(val_labels, model_7_preds)\n",
        "model_7_results"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.34645669291339,\n",
              " 'f1': 0.7811856084066165,\n",
              " 'precision': 0.7861644127328657,\n",
              " 'recall': 0.7834645669291339}"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tliuh0HJPcuu"
      },
      "source": [
        "`model_7` with 10 percent of the data performs slightly better than `model_6`... something doesn't feel right..\n",
        "\n",
        "What is actually happening here is that we managed to get some of the validation data to the training data because we import them from the same dictionary which is `train_data_shuffled`, which is like cheating (data leaks). \n",
        "\n",
        "It should perform slightly less than the actual training data (100% of the data).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlbncHDyPZzb",
        "outputId": "c38f555e-1e12-4088-9dd5-1e96d39dbe9a"
      },
      "source": [
        "model_6_results"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.36482939632546,\n",
              " 'f1': 0.8126248998925568,\n",
              " 'precision': 0.8145308821695579,\n",
              " 'recall': 0.8136482939632546}"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pnf3vH8Pb7Y"
      },
      "source": [
        "## Comparing the performance of each of our models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "9eAS-jSFeg7J",
        "outputId": "77fe0fa1-f26e-41f6-d551-690360ca68c1"
      },
      "source": [
        "# Combine model results into a dataframe\n",
        "all_model_results = pd.DataFrame({\"0_baseline\": baseline_results,\n",
        "                                  \"1_simple_dense\": model_1_results,\n",
        "                                  \"2_lstm\": model_2_results,\n",
        "                                  \"3_gru\": results_model_3,\n",
        "                                  \"4_bidirectional\": model_4_results,\n",
        "                                  \"5_conv1d\": model_5_results,\n",
        "                                  \"6_tf_hub_use_encoder\": model_6_results,\n",
        "                                  \"7_tf_hub_use_encoder_10_percent_data\": model_7_results})\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_baseline</th>\n",
              "      <td>79.265092</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_simple_dense</th>\n",
              "      <td>78.215223</td>\n",
              "      <td>0.785666</td>\n",
              "      <td>0.782152</td>\n",
              "      <td>0.779522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_lstm</th>\n",
              "      <td>78.215223</td>\n",
              "      <td>0.787276</td>\n",
              "      <td>0.782152</td>\n",
              "      <td>0.778937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_gru</th>\n",
              "      <td>77.165354</td>\n",
              "      <td>0.772065</td>\n",
              "      <td>0.771654</td>\n",
              "      <td>0.770293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_bidirectional</th>\n",
              "      <td>77.034121</td>\n",
              "      <td>0.771370</td>\n",
              "      <td>0.770341</td>\n",
              "      <td>0.768571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_conv1d</th>\n",
              "      <td>75.065617</td>\n",
              "      <td>0.750183</td>\n",
              "      <td>0.750656</td>\n",
              "      <td>0.750086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_tf_hub_use_encoder</th>\n",
              "      <td>81.364829</td>\n",
              "      <td>0.814531</td>\n",
              "      <td>0.813648</td>\n",
              "      <td>0.812625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_tf_hub_use_encoder_10_percent_data</th>\n",
              "      <td>78.346457</td>\n",
              "      <td>0.786164</td>\n",
              "      <td>0.783465</td>\n",
              "      <td>0.781186</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       accuracy  precision    recall        f1\n",
              "0_baseline                            79.265092   0.811139  0.792651  0.786219\n",
              "1_simple_dense                        78.215223   0.785666  0.782152  0.779522\n",
              "2_lstm                                78.215223   0.787276  0.782152  0.778937\n",
              "3_gru                                 77.165354   0.772065  0.771654  0.770293\n",
              "4_bidirectional                       77.034121   0.771370  0.770341  0.768571\n",
              "5_conv1d                              75.065617   0.750183  0.750656  0.750086\n",
              "6_tf_hub_use_encoder                  81.364829   0.814531  0.813648  0.812625\n",
              "7_tf_hub_use_encoder_10_percent_data  78.346457   0.786164  0.783465  0.781186"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SgKZMPDet_x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "d46e37bc-d58e-4f3e-83c9-080f66e1993a"
      },
      "source": [
        "# Reduce the accuracy to the same scales as other metrics\n",
        "all_model_results['accuracy'] = all_model_results[\"accuracy\"] / 100\n",
        "all_model_results"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_baseline</th>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.811139</td>\n",
              "      <td>0.792651</td>\n",
              "      <td>0.786219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_simple_dense</th>\n",
              "      <td>0.782152</td>\n",
              "      <td>0.785666</td>\n",
              "      <td>0.782152</td>\n",
              "      <td>0.779522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_lstm</th>\n",
              "      <td>0.782152</td>\n",
              "      <td>0.787276</td>\n",
              "      <td>0.782152</td>\n",
              "      <td>0.778937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_gru</th>\n",
              "      <td>0.771654</td>\n",
              "      <td>0.772065</td>\n",
              "      <td>0.771654</td>\n",
              "      <td>0.770293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_bidirectional</th>\n",
              "      <td>0.770341</td>\n",
              "      <td>0.771370</td>\n",
              "      <td>0.770341</td>\n",
              "      <td>0.768571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_conv1d</th>\n",
              "      <td>0.750656</td>\n",
              "      <td>0.750183</td>\n",
              "      <td>0.750656</td>\n",
              "      <td>0.750086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_tf_hub_use_encoder</th>\n",
              "      <td>0.813648</td>\n",
              "      <td>0.814531</td>\n",
              "      <td>0.813648</td>\n",
              "      <td>0.812625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_tf_hub_use_encoder_10_percent_data</th>\n",
              "      <td>0.783465</td>\n",
              "      <td>0.786164</td>\n",
              "      <td>0.783465</td>\n",
              "      <td>0.781186</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      accuracy  precision    recall        f1\n",
              "0_baseline                            0.792651   0.811139  0.792651  0.786219\n",
              "1_simple_dense                        0.782152   0.785666  0.782152  0.779522\n",
              "2_lstm                                0.782152   0.787276  0.782152  0.778937\n",
              "3_gru                                 0.771654   0.772065  0.771654  0.770293\n",
              "4_bidirectional                       0.770341   0.771370  0.770341  0.768571\n",
              "5_conv1d                              0.750656   0.750183  0.750656  0.750086\n",
              "6_tf_hub_use_encoder                  0.813648   0.814531  0.813648  0.812625\n",
              "7_tf_hub_use_encoder_10_percent_data  0.783465   0.786164  0.783465  0.781186"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "id": "MJXEyRQCftZH",
        "outputId": "3a07bfab-098f-4afd-b3c7-1bd05bb33dce"
      },
      "source": [
        "# Plot and compare all of the model results\n",
        "all_model_results.plot(kind=\"bar\", figsize=(10,7)).legend(bbox_to_anchor=(1.0, 1.0));"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "id": "IexNO20NgFYc",
        "outputId": "344eacce-65fb-4ff6-da63-3f1b8585986c"
      },
      "source": [
        "# Sort model results by f1-score\n",
        "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10,7));"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAYnUzRJg1g2"
      },
      "source": [
        "## Uploading our model training logs to TensorBoard.dev"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AghYXq2DhX8a"
      },
      "source": [
        "!tensorboard dev upload --logdir ./model_logs/ \\\n",
        "  --name \"NLP Modelling Experiments from NLP Getting Started dataset (Kaggle)\" \\\n",
        "  --description \"A brief practice and understanding of NLP as a beginner\" \\\n",
        "  --one_shot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZM4eicfhyKJ"
      },
      "source": [
        "The experiment results: https://tensorboard.dev/experiment/s8NXlmxAQz6GdB9JY5SOmw/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCzhmvhqKspV"
      },
      "source": [
        "## The speed/score tradeoff\n",
        "\n",
        "Would you want to use a model that has the best acurracy but slow to predict or choose a model that is fast to predict but is low on accuracy?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta8B3PkyKvPJ"
      },
      "source": [
        "import time\n",
        "def pred_timer(model, samples):\n",
        "  \"\"\"\n",
        "  Times how long a model takes to make predictions on samples.\n",
        "  \"\"\"\n",
        "  start_time = time.perf_counter() # get start time\n",
        "  model.predict(samples)\n",
        "  end_time = time.perf_counter()\n",
        "  total_time = end_time - start_time\n",
        "  time_per_pred = total_time / len(samples)\n",
        "  return total_time, time_per_pred"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZQmVYNGMELu",
        "outputId": "37c87c14-3e56-41c8-8098-db9a2b45b63a"
      },
      "source": [
        "# Calculate TF Hub USE time per pred\n",
        "model_6_total_pred_time, model_6_time_per_pred = pred_timer(model_6, val_sentences)\n",
        "model_6_total_pred_time, model_6_time_per_pred"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.35138246200000367, 0.00046113183989501794)"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W-Ct0bSMHkR",
        "outputId": "9417d1b7-0054-4460-c1b4-bb4571b009a6"
      },
      "source": [
        "# Calculate our baseline model times per pred\n",
        "model_0_total_pred_time, model_0_time_per_pred = pred_timer(model_0, val_sentences)\n",
        "model_0_total_pred_time, model_0_time_per_pred"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.03341939699998875, 4.385747637793799e-05)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCQrdqpcMmLD"
      },
      "source": [
        "Our baseline model is faster than our USE TF Hub model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "3nHOK_rTMfFF",
        "outputId": "ef109506-49b3-416b-8120-97713123b25a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.scatter(model_0_time_per_pred, baseline_results[\"f1\"], label=\"baseline\")\n",
        "plt.scatter(model_6_time_per_pred, model_6_results['f1'], label=\"tf_hub_sentence_encoder\")\n",
        "plt.legend()\n",
        "plt.title(\"f1-score vs time per prediction\")\n",
        "plt.xlabel(\"Time per prediction\")\n",
        "plt.ylabel(\"f1-score\");"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpyxESJsNndx"
      },
      "source": [
        "*Is it worth to use the fastest model but slighty worse rate or use the best accuracy model with slightly slower prediction?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WBmXlpuNc04"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}